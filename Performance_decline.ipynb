{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Developing a hypothesis for performance decline in a session and proving it using statistical tests\n",
        "<b>Null Hypothesis (H₀)</b>: The average accuracy/WPM/consistency in the first half of a session is equal to or more than the average accuracy/WPM in the second half of the session.\n",
        "\n",
        "<b>Alternative Hypothesis (H₁)</b>: The average accuracy/WPM/consistency in the first half of a session is lesser than the average accuracy/WPM in the second half of the session."
      ],
      "metadata": {
        "id": "-ApdRQ7PYq92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "folder_id = \"1G7YDTrD_UNCUFiOs5ed4JV1QtRXaAEU0\"\n",
        "output = \"datasets\"\n",
        "gdown.download_folder(f\"https://drive.google.com/drive/folders/{folder_id}\", output=output, quiet=False, use_cookies=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CUZ9yY0UaVH3",
        "outputId": "2cf0c88c-6d96-43b3-dcb5-faacb46d8ec7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1DAPRaVIVUmJME2LHfNfwwveB4mk5VOPx Subject_A_Results.csv\n",
            "Processing file 1hf-mQ-rTuKlFlkMd8Nld77s8HbMs01NV Subject_B_Results.csv\n",
            "Processing file 1zOQNeWfoew5LoT2AbSHqXlpRVYfiNKYg Subject_C_Results.csv\n",
            "Processing file 18gvXYZ15sfvGkPIJTYb3FLwwTAdvesCr Subject_D_Results.csv\n",
            "Processing file 19R_ckXXDHpanEX04UqNfwlA90jFxPaDR Subject_E_Results.csv\n",
            "Processing file 1o2fkODEhX_4ObhHX1ghVAgk390BvCYoD Subject_F_Results.csv\n",
            "Processing file 1tSKEy03Tcjiw9iJjpxH03plDjZRsgZZh Subject_G_Results.csv\n",
            "Processing file 18NMwG0OHknGMDfFczZ5xntwFGEee_rcj Subject_H_Results.csv\n",
            "Processing file 16uSR_2cqPTtCyUklqqttsNPZvrzads-k Subject_I_Results.csv\n",
            "Processing file 1BnJ8m-YIVU_D7rXj46F4oLn1PMeXrOP1 Subject_J_Results.csv\n",
            "Processing file 1RjLMAKuzuYk4E32wY6MvqP21WnmuKkVn Subject_K_Results.csv\n",
            "Processing file 16PBRPMRWzpVjBJxs78zK5iaQ-Dc_vsjF Subject_L_Results.csv\n",
            "Processing file 1JRc1mz1ODZeURfQGaMXdLkv9F73vKZ1z Subject_M_Results.csv\n",
            "Processing file 1Aib17o9nXQAYNWiDwo-E0wd_NBvnOl9U Subject_N_Results.csv\n",
            "Processing file 15510yLbGu1urZ3yzzxiFRu2vo0EHG40a Subject_O_Results.csv\n",
            "Processing file 1KnXsr1LKcLjYSB8g5AyMslohts_5Pf_4 Subject_P_Results.csv\n",
            "Processing file 1Rd4r9Yz04eUcrNCV8RuWjpOkn1Ys4wSR Subject_Q_Results.csv\n",
            "Processing file 1A3YDP4MYlnYbLGymsKxulExV1_jIJARM Subject_R_Results.csv\n",
            "Processing file 1_kMLywOLRoh2Z_ijlfOfwp692L_etcYT Subject_S_Results.csv\n",
            "Processing file 1mt5WJVxBFnViINcDUMhbaiOZ7MS3z4gW Subject_T_Results.csv\n",
            "Processing file 1luHPltWWB2irRbyq2lFc2YyffvZTPD6y Subject_U_Results.csv\n",
            "Processing file 1-4JVdNHUfQIwkkR1N3CY-jCuVFRs7yxS Subject_V_Results.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1DAPRaVIVUmJME2LHfNfwwveB4mk5VOPx\n",
            "To: /content/datasets/Subject_A_Results.csv\n",
            "100%|██████████| 67.6k/67.6k [00:00<00:00, 59.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hf-mQ-rTuKlFlkMd8Nld77s8HbMs01NV\n",
            "To: /content/datasets/Subject_B_Results.csv\n",
            "100%|██████████| 152k/152k [00:00<00:00, 74.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1zOQNeWfoew5LoT2AbSHqXlpRVYfiNKYg\n",
            "To: /content/datasets/Subject_C_Results.csv\n",
            "100%|██████████| 147k/147k [00:00<00:00, 40.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=18gvXYZ15sfvGkPIJTYb3FLwwTAdvesCr\n",
            "To: /content/datasets/Subject_D_Results.csv\n",
            "100%|██████████| 155k/155k [00:00<00:00, 28.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19R_ckXXDHpanEX04UqNfwlA90jFxPaDR\n",
            "To: /content/datasets/Subject_E_Results.csv\n",
            "100%|██████████| 157k/157k [00:00<00:00, 53.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1o2fkODEhX_4ObhHX1ghVAgk390BvCYoD\n",
            "To: /content/datasets/Subject_F_Results.csv\n",
            "100%|██████████| 149k/149k [00:00<00:00, 58.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1tSKEy03Tcjiw9iJjpxH03plDjZRsgZZh\n",
            "To: /content/datasets/Subject_G_Results.csv\n",
            "100%|██████████| 105k/105k [00:00<00:00, 68.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=18NMwG0OHknGMDfFczZ5xntwFGEee_rcj\n",
            "To: /content/datasets/Subject_H_Results.csv\n",
            "100%|██████████| 78.4k/78.4k [00:00<00:00, 67.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16uSR_2cqPTtCyUklqqttsNPZvrzads-k\n",
            "To: /content/datasets/Subject_I_Results.csv\n",
            "100%|██████████| 42.7k/42.7k [00:00<00:00, 54.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1BnJ8m-YIVU_D7rXj46F4oLn1PMeXrOP1\n",
            "To: /content/datasets/Subject_J_Results.csv\n",
            "100%|██████████| 152k/152k [00:00<00:00, 56.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1RjLMAKuzuYk4E32wY6MvqP21WnmuKkVn\n",
            "To: /content/datasets/Subject_K_Results.csv\n",
            "100%|██████████| 150k/150k [00:00<00:00, 80.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16PBRPMRWzpVjBJxs78zK5iaQ-Dc_vsjF\n",
            "To: /content/datasets/Subject_L_Results.csv\n",
            "100%|██████████| 152k/152k [00:00<00:00, 39.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1JRc1mz1ODZeURfQGaMXdLkv9F73vKZ1z\n",
            "To: /content/datasets/Subject_M_Results.csv\n",
            "100%|██████████| 150k/150k [00:00<00:00, 44.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Aib17o9nXQAYNWiDwo-E0wd_NBvnOl9U\n",
            "To: /content/datasets/Subject_N_Results.csv\n",
            "100%|██████████| 149k/149k [00:00<00:00, 35.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15510yLbGu1urZ3yzzxiFRu2vo0EHG40a\n",
            "To: /content/datasets/Subject_O_Results.csv\n",
            "100%|██████████| 43.8k/43.8k [00:00<00:00, 56.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1KnXsr1LKcLjYSB8g5AyMslohts_5Pf_4\n",
            "To: /content/datasets/Subject_P_Results.csv\n",
            "100%|██████████| 7.15k/7.15k [00:00<00:00, 3.52MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Rd4r9Yz04eUcrNCV8RuWjpOkn1Ys4wSR\n",
            "To: /content/datasets/Subject_Q_Results.csv\n",
            "100%|██████████| 4.40k/4.40k [00:00<00:00, 11.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1A3YDP4MYlnYbLGymsKxulExV1_jIJARM\n",
            "To: /content/datasets/Subject_R_Results.csv\n",
            "100%|██████████| 51.1k/51.1k [00:00<00:00, 35.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1_kMLywOLRoh2Z_ijlfOfwp692L_etcYT\n",
            "To: /content/datasets/Subject_S_Results.csv\n",
            "100%|██████████| 34.9k/34.9k [00:00<00:00, 48.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1mt5WJVxBFnViINcDUMhbaiOZ7MS3z4gW\n",
            "To: /content/datasets/Subject_T_Results.csv\n",
            "100%|██████████| 25.6k/25.6k [00:00<00:00, 13.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1luHPltWWB2irRbyq2lFc2YyffvZTPD6y\n",
            "To: /content/datasets/Subject_U_Results.csv\n",
            "100%|██████████| 148k/148k [00:00<00:00, 80.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-4JVdNHUfQIwkkR1N3CY-jCuVFRs7yxS\n",
            "To: /content/datasets/Subject_V_Results.csv\n",
            "100%|██████████| 152k/152k [00:00<00:00, 47.9MB/s]\n",
            "Download completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['datasets/Subject_A_Results.csv',\n",
              " 'datasets/Subject_B_Results.csv',\n",
              " 'datasets/Subject_C_Results.csv',\n",
              " 'datasets/Subject_D_Results.csv',\n",
              " 'datasets/Subject_E_Results.csv',\n",
              " 'datasets/Subject_F_Results.csv',\n",
              " 'datasets/Subject_G_Results.csv',\n",
              " 'datasets/Subject_H_Results.csv',\n",
              " 'datasets/Subject_I_Results.csv',\n",
              " 'datasets/Subject_J_Results.csv',\n",
              " 'datasets/Subject_K_Results.csv',\n",
              " 'datasets/Subject_L_Results.csv',\n",
              " 'datasets/Subject_M_Results.csv',\n",
              " 'datasets/Subject_N_Results.csv',\n",
              " 'datasets/Subject_O_Results.csv',\n",
              " 'datasets/Subject_P_Results.csv',\n",
              " 'datasets/Subject_Q_Results.csv',\n",
              " 'datasets/Subject_R_Results.csv',\n",
              " 'datasets/Subject_S_Results.csv',\n",
              " 'datasets/Subject_T_Results.csv',\n",
              " 'datasets/Subject_U_Results.csv',\n",
              " 'datasets/Subject_V_Results.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "from scipy.stats import ttest_rel\n",
        "import numpy as np\n",
        "\n",
        "def calculate_cohens_d(group1, group2):\n",
        "    \"\"\"Calculate Cohen's d for two related groups.\"\"\"\n",
        "    diff = np.array(group1) - np.array(group2)\n",
        "    return np.mean(diff) / np.std(diff, ddof=1)\n",
        "\n",
        "def split_and_test(aggregated_sessions):\n",
        "    \"\"\"Split the aggregated sessions, compute the mean for each half, and perform statistical tests.\"\"\"\n",
        "    first_half_wpm = []\n",
        "    second_half_wpm = []\n",
        "    first_half_accuracy = []\n",
        "    second_half_accuracy = []\n",
        "    first_half_consistency = []\n",
        "    second_half_consistency = []\n",
        "\n",
        "    for session in aggregated_sessions:\n",
        "        if len(session) < 8:\n",
        "            continue\n",
        "\n",
        "        mid_point = len(session) //2\n",
        "        first_half = session[:mid_point]\n",
        "        second_half = session[mid_point:]\n",
        "\n",
        "        first_half_wpm.append(first_half['wpm'].mean())\n",
        "        second_half_wpm.append(second_half['wpm'].mean())\n",
        "\n",
        "        first_half_accuracy.append(first_half['acc'].mean())\n",
        "        second_half_accuracy.append(second_half['acc'].mean())\n",
        "\n",
        "        first_half_consistency.append(first_half['consistency'].mean())\n",
        "        second_half_consistency.append(second_half['consistency'].mean())\n",
        "\n",
        "    wpm_tstat, wpm_pvalue = ttest_rel(first_half_wpm, second_half_wpm)\n",
        "    accuracy_tstat, accuracy_pvalue = ttest_rel(first_half_accuracy, second_half_accuracy)\n",
        "    consistency_tstat, consistency_pvalue = ttest_rel(first_half_consistency, second_half_consistency)\n",
        "\n",
        "    print(\"Overall Typing Speed (WPM):\")\n",
        "    print(f\"t-statistic = {wpm_tstat:.3f}, p-value = {wpm_pvalue:.3f}\")\n",
        "    print(\"Overall Accuracy:\")\n",
        "    print(f\"t-statistic = {accuracy_tstat:.3f}, p-value = {accuracy_pvalue:.3f}\")\n",
        "    print(\"Overall Consistency: \")\n",
        "    print(f\"t-statistic = {consistency_tstat:.3f}, p-value = {consistency_pvalue:.3f}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    wpm_cohen_d = calculate_cohens_d(first_half_wpm, second_half_wpm)\n",
        "    accuracy_cohen_d = calculate_cohens_d(first_half_accuracy, second_half_accuracy)\n",
        "    consistency_cohen_d = calculate_cohens_d(first_half_consistency, second_half_consistency)\n",
        "\n",
        "    print(f\"Effect Size (Cohen's d) for WPM: {wpm_cohen_d:.3f}\")\n",
        "    print(f\"Effect Size (Cohen's d) for Accuracy: {accuracy_cohen_d:.3f}\")\n",
        "    print(f\"Effect Size (Cohen's d) for Consistency: {consistency_cohen_d:.3f}\")\n",
        "\n",
        "\n",
        "def subject_session_details(data):\n",
        "    window_size = 30 * 60 * 1000  # 30 minutes in milliseconds\n",
        "    sessions = []\n",
        "    curr_session = []\n",
        "\n",
        "    for _, row in data.iterrows():\n",
        "        if len(curr_session) == 0 or abs(row['timestamp'] - curr_session[0]['timestamp']) < window_size:\n",
        "            curr_session.append(row)\n",
        "        else:\n",
        "            if len(curr_session) != 0:\n",
        "                sessions.append(pd.DataFrame(curr_session))\n",
        "                curr_session = [row]\n",
        "\n",
        "    if curr_session:  # Add the last session\n",
        "        sessions.append(pd.DataFrame(curr_session))\n",
        "    sessions = [session for session in sessions if len(session) >= 8]\n",
        "    print(f\"Number of sessions with at least 8 tests: {len(sessions)}\")\n",
        "\n",
        "    return sessions\n",
        "\n",
        "def process_csv_files(folder_path):\n",
        "    \"\"\"Aggregate sessions from all CSV files.\"\"\"\n",
        "    csv_files = glob.glob(f\"{folder_path}/*.csv\")\n",
        "    aggregated_sessions = []\n",
        "\n",
        "    for file in csv_files:\n",
        "        try:\n",
        "            print(f\"Processing file: {file}\")\n",
        "            data = pd.read_csv(file)\n",
        "            sessions = subject_session_details(data)\n",
        "            aggregated_sessions.extend(sessions)\n",
        "        except pd.errors.EmptyDataError:\n",
        "            print(f\"Warning: File '{file}' is empty. Skipping.\")\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while processing '{file}': {e}\")\n",
        "    split_and_test(aggregated_sessions)\n",
        "\n",
        "process_csv_files(\"datasets\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osU_I1skZ548",
        "outputId": "66270721-db6c-4aea-9572-a031b3eaa27b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: datasets/Subject_Q_Results.csv\n",
            "Number of sessions with at least 8 tests: 0\n",
            "Processing file: datasets/Subject_N_Results.csv\n",
            "Number of sessions with at least 8 tests: 40\n",
            "Processing file: datasets/Subject_T_Results.csv\n",
            "Number of sessions with at least 8 tests: 2\n",
            "Processing file: datasets/Subject_A_Results.csv\n",
            "Number of sessions with at least 8 tests: 22\n",
            "Processing file: datasets/Subject_S_Results.csv\n",
            "Number of sessions with at least 8 tests: 9\n",
            "Processing file: datasets/Subject_J_Results.csv\n",
            "Number of sessions with at least 8 tests: 41\n",
            "Processing file: datasets/Subject_V_Results.csv\n",
            "Number of sessions with at least 8 tests: 50\n",
            "Processing file: datasets/Subject_G_Results.csv\n",
            "Number of sessions with at least 8 tests: 47\n",
            "Processing file: datasets/Subject_D_Results.csv\n",
            "Number of sessions with at least 8 tests: 26\n",
            "Processing file: datasets/Subject_P_Results.csv\n",
            "Number of sessions with at least 8 tests: 0\n",
            "Processing file: datasets/Subject_U_Results.csv\n",
            "Number of sessions with at least 8 tests: 20\n",
            "Processing file: datasets/Subject_B_Results.csv\n",
            "Number of sessions with at least 8 tests: 36\n",
            "Processing file: datasets/Subject_M_Results.csv\n",
            "Number of sessions with at least 8 tests: 44\n",
            "Processing file: datasets/Subject_E_Results.csv\n",
            "Number of sessions with at least 8 tests: 23\n",
            "Processing file: datasets/Subject_R_Results.csv\n",
            "Number of sessions with at least 8 tests: 8\n",
            "Processing file: datasets/Subject_I_Results.csv\n",
            "Number of sessions with at least 8 tests: 11\n",
            "Processing file: datasets/Subject_K_Results.csv\n",
            "Number of sessions with at least 8 tests: 26\n",
            "Processing file: datasets/Subject_O_Results.csv\n",
            "Number of sessions with at least 8 tests: 2\n",
            "Processing file: datasets/Subject_L_Results.csv\n",
            "Number of sessions with at least 8 tests: 36\n",
            "Processing file: datasets/Subject_F_Results.csv\n",
            "Number of sessions with at least 8 tests: 47\n",
            "Processing file: datasets/Subject_H_Results.csv\n",
            "Number of sessions with at least 8 tests: 5\n",
            "Processing file: datasets/Subject_C_Results.csv\n",
            "Number of sessions with at least 8 tests: 33\n",
            "Overall Typing Speed (WPM):\n",
            "t-statistic = 0.633, p-value = 0.527\n",
            "Overall Accuracy:\n",
            "t-statistic = -0.757, p-value = 0.449\n",
            "Overall Consistency: \n",
            "t-statistic = 0.206, p-value = 0.837\n",
            "--------------------------------------------------\n",
            "Effect Size (Cohen's d) for WPM: 0.028\n",
            "Effect Size (Cohen's d) for Accuracy: -0.033\n",
            "Effect Size (Cohen's d) for Consistency: 0.009\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "from scipy.stats import wilcoxon\n",
        "\n",
        "def filter_and_session_data(data):\n",
        "    window_size = 30 * 60 * 1000  # 30 minutes in milliseconds\n",
        "    sessions = []\n",
        "    curr_session = []\n",
        "\n",
        "    for _, row in data.iterrows():\n",
        "        if len(curr_session) == 0 or abs(row['timestamp'] - curr_session[0]['timestamp']) < window_size:\n",
        "            curr_session.append(row)\n",
        "        else:\n",
        "            if len(curr_session) != 0:\n",
        "                sessions.append(pd.DataFrame(curr_session))\n",
        "            curr_session = [row]\n",
        "\n",
        "    if curr_session:  # Add the last session\n",
        "        sessions.append(pd.DataFrame(curr_session))\n",
        "\n",
        "    # Filter out sessions with less than 8 tests\n",
        "    sessions = [session for session in sessions if len(session) >= 8]\n",
        "    print(f\"Number of sessions with at least 8 tests: {len(sessions)}\")\n",
        "\n",
        "    return sessions\n",
        "\n",
        "def test_restart_count_in_first_vs_second_half(sessions):\n",
        "    \"\"\"Perform Wilcoxon signed-rank test to compare sum of restartCount in the first and second half of each session.\"\"\"\n",
        "    first_half_restart_count = []\n",
        "    second_half_restart_count = []\n",
        "\n",
        "    for session in sessions:\n",
        "        if len(session) < 8:\n",
        "            continue\n",
        "\n",
        "        mid_point = len(session) // 2\n",
        "        first_half = session[:mid_point]\n",
        "        second_half = session[mid_point:]\n",
        "\n",
        "        first_half_restart_count.append(first_half['restartCount'].sum())\n",
        "        second_half_restart_count.append(second_half['restartCount'].sum())\n",
        "\n",
        "    stat, p_value = wilcoxon(first_half_restart_count, second_half_restart_count, alternative='greater')\n",
        "\n",
        "    print(\"Wilcoxon Signed-Rank Test for Sum of Restart Count in Second Half vs First Half:\")\n",
        "    print(f\"Statistic = {stat:.3f}, p-value = {p_value:.3f}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "def process_csv_files(folder_path):\n",
        "    \"\"\"Aggregate sessions from all CSV files and perform statistical tests.\"\"\"\n",
        "    csv_files = glob.glob(f\"{folder_path}/*.csv\")\n",
        "    aggregated_sessions = []\n",
        "\n",
        "    for file in csv_files:\n",
        "        try:\n",
        "            print(f\"Processing file: {file}\")\n",
        "            data = pd.read_csv(file)\n",
        "            sessions = filter_and_session_data(data)\n",
        "            aggregated_sessions.extend(sessions)\n",
        "        except pd.errors.EmptyDataError:\n",
        "            print(f\"Warning: File '{file}' is empty. Skipping.\")\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while processing '{file}': {e}\")\n",
        "    test_restart_count_in_first_vs_second_half(aggregated_sessions)\n",
        "\n",
        "process_csv_files(\"datasets\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DM63umWlZ8sh",
        "outputId": "ed014963-5407-4087-9919-df13fb4a71c1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: datasets/Subject_Q_Results.csv\n",
            "Number of sessions with at least 8 tests: 0\n",
            "Processing file: datasets/Subject_N_Results.csv\n",
            "Number of sessions with at least 8 tests: 40\n",
            "Processing file: datasets/Subject_T_Results.csv\n",
            "Number of sessions with at least 8 tests: 2\n",
            "Processing file: datasets/Subject_A_Results.csv\n",
            "Number of sessions with at least 8 tests: 22\n",
            "Processing file: datasets/Subject_S_Results.csv\n",
            "Number of sessions with at least 8 tests: 9\n",
            "Processing file: datasets/Subject_J_Results.csv\n",
            "Number of sessions with at least 8 tests: 41\n",
            "Processing file: datasets/Subject_V_Results.csv\n",
            "Number of sessions with at least 8 tests: 50\n",
            "Processing file: datasets/Subject_G_Results.csv\n",
            "Number of sessions with at least 8 tests: 47\n",
            "Processing file: datasets/Subject_D_Results.csv\n",
            "Number of sessions with at least 8 tests: 26\n",
            "Processing file: datasets/Subject_P_Results.csv\n",
            "Number of sessions with at least 8 tests: 0\n",
            "Processing file: datasets/Subject_U_Results.csv\n",
            "Number of sessions with at least 8 tests: 20\n",
            "Processing file: datasets/Subject_B_Results.csv\n",
            "Number of sessions with at least 8 tests: 36\n",
            "Processing file: datasets/Subject_M_Results.csv\n",
            "Number of sessions with at least 8 tests: 44\n",
            "Processing file: datasets/Subject_E_Results.csv\n",
            "Number of sessions with at least 8 tests: 23\n",
            "Processing file: datasets/Subject_R_Results.csv\n",
            "Number of sessions with at least 8 tests: 8\n",
            "Processing file: datasets/Subject_I_Results.csv\n",
            "Number of sessions with at least 8 tests: 11\n",
            "Processing file: datasets/Subject_K_Results.csv\n",
            "Number of sessions with at least 8 tests: 26\n",
            "Processing file: datasets/Subject_O_Results.csv\n",
            "Number of sessions with at least 8 tests: 2\n",
            "Processing file: datasets/Subject_L_Results.csv\n",
            "Number of sessions with at least 8 tests: 36\n",
            "Processing file: datasets/Subject_F_Results.csv\n",
            "Number of sessions with at least 8 tests: 47\n",
            "Processing file: datasets/Subject_H_Results.csv\n",
            "Number of sessions with at least 8 tests: 5\n",
            "Processing file: datasets/Subject_C_Results.csv\n",
            "Number of sessions with at least 8 tests: 33\n",
            "Wilcoxon Signed-Rank Test for Sum of Restart Count in Second Half vs First Half:\n",
            "Statistic = 46025.000, p-value = 0.547\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "duX1eWSQaDhU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}